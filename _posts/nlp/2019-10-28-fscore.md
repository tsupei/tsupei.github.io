---
layout: article_post
title:  "Fscore / Precision / Recall"
categories: nlp
excerpt_separator: <!--more-->
tags: Evaluation machine-learning 
---

繼續上次混淆矩陣的主題，我們快速複習一下，二元混淆矩陣包含四個要素`:TP(True Positive)`, `TN(True Negative)`, `FP(False Positive)`, `FN(False Negative)`

但光是直接看這些數值，我們很難一眼看出一個分類模型的好壞，所以我們通常會透過`Recall`, `Precision`, `F1-score`這些指標來評估一個模型的好壞

$$ \textit{Recall(召回率)} = \frac{TP}{(TP + FN )} $$

$$ \textit{Precision(準確率)} = \frac{TP}{(TP+FP)} $$

$$ \textit{F1-score} = \frac{ 2 \times \textit{Precision} \times \textit{Recall} }{(Precision + Recall)} $$

召回率是在所有正樣本當中，能夠預測多少正樣本的比例，準確率為在所有預測為正樣本中，有多少為正樣本

所以拿我們上次的例子來說，在小明家的門禁系統中，哪個比較重要呢？

以這個例子來說，準確率應比較重要，我們希望判定成正樣本就一定要是正確的，不要有小王的臉可以打開小明家的門的情況，而召回率低的話，也不過是常常無法判斷出來小明的臉，但至少不是誤判

---

讓我們再舉一個實際在NLP領域上會遇到的例子

{% include widget/excerpt.html text="假設我們今天要做一個NER(命名實體識別)的模型，每個字我們都會輸出一個標籤，如果該字我們認為不屬於命名實體的任一部分，也會有一個標籤代表非標籤(ex. UNK)，那麼你是否能解釋一下，一個Precision高而Recall低的模型跟一個Recall高而Precision低的模型，分別代表什麼意義呢？" %}

前者，可以看作一個比較謹慎的模型，雖然常常沒辦法抓出命名實體，但只要有抓出幾乎都是正確的(Precision高)，而後者則是一個寬鬆的模型，雖然有時候會抓錯，但幾乎該抓的都有抓到(Recall高)

在極端的場合，兩個模型都是不好的，以NER這個例子，前者可能幾乎無法預測出命名實體，那等於沒有功用，後者可能預測錯誤太多，也無法拿來使用，這時候我們就希望有一個指標，能夠調和兩者

F1-score則是兩者的調和平均數，算是一個比較概略的指標來看這個模型的表現

