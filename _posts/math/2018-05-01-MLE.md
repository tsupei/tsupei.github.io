---
layout: article_post
title:  "Maximum Likelihood Estimation(MLE)"
categories: math
tags: Probability MLE Distribution Likelihood
excerpt_separator: <!--more-->
---

`最大似然估計(MLE)`常常被使用在神經網路學習中，常常`損失函式(Loss Function)`會是似然函數，因此，這篇文章讓我們深入了解似然性、似然函數、最大似然估計這些概念吧!

<!--more-->

### 似然函數(Likelihood)
---

{% include widget/excerpt.html text="機率用於在已知一些參數的情況下，預測接下來的觀測所得到的結果，而似然性則是用於在已知某些觀測所得到的結果時，對有關事物的性質的參數進行估計" %}

關於什麼是`Likelihood`，什麼是`Maximum Likelihood Estimation`

[維基百科](https://zh.wikipedia.org/wiki/最大似然估计)寫得非常完整，可以先去複習一下再回來看

但是在關於`似然函數`的定義，我會建議參考[這篇](https://www.zhihu.com/question/54082000)

$$ L( \theta \mid x) = f(x \mid \theta) $$
	
$$ x \textit{是聯合樣本隨機變量} X \textit{取到的值，} X = x $$

$$ \theta \textit{是未知參數} $$

$$ f \textit{是一個密度函數，給定參數} \theta \textit{下關於聯合樣本值} x \textit{的聯合密度函數} $$

雖然`函數值`相等，但兩個函數是完全不同的

$L$是`對 $\theta $`的函數，$f$是`對 $x$`的函數，也可以看成兩種不同的切入角度，$L$是給定觀測結果後，去預測參數$\theta$，$f$則是給定參數$\theta$，去得到結果的機率是多少

---

假設$f$是`機率質量函數`，我們可以寫成

$$ L( \theta \mid x) = P(X = x \mid \theta) $$

**注意，這邊的$\mid$，表示給定$\theta$的意思**

所以，舉例來說，在一個公平的投擲硬幣的例子中

前三次結果都是正面，我們記為HHH

$$ L(p = 0.5 \mid HHH) = P(HHH \mid p = 0.5) = 0.125 $$

我們對這個式子可以有兩種解釋

1. 在給定結果HHH時，骰子骰到正面機率為0.5的似然性是0.125
2. 在給定骰子骰到正面機率為0.5時，得到結果HHH的機率為0.125

所以回到觀點1，從這樣的觀點，當我們得到HHH的結果時

骰子骰到正面機率最有可能會是1

換句話說，這最有可能是一個怎麼骰到骰到正面的骰子

$$ L(p = 1 \mid HHH) = P(HHH \mid p = 1) = 1 * 1 * 1 = 1 $$

*注意：似然函數並不被要求滿足歸一性*

$L(p = 1 \mid HHH)$等於1，大於$L(p=0.5 \mid HHH)$的0.125

### 隨機變數(Random Variable)
---

離散隨機變數(discrete random variable)

$$ \textit{若是隨機變數X的取值是有限或可數的} $$

$$ X = \left \{ x_{1}, x_{2}, x_{3}, ..., x_{n} \right \} $$

$$ \textit{則稱Ｘ為離散隨機變數} $$

連續隨機變數(continuous random variable)

$$ \textit{若隨機變數Ｘ是由全部實數或某一部分區間所組成的話} $$

$$ X = \{x \mid a <= x <= b \}, -inf < a,b < inf $$

$$ \textit{則稱Ｘ為連續隨機變數} $$

### 機率質量函數(pmf)、機率密度函數(pdf)
---

關於[機率質量函數](https://zh.wikipedia.org/wiki/概率质量函数)跟[機率密度函數](https://zh.wikipedia.org/wiki/機率密度函數)的定義跟性質非常重要，但在這裡不加贅述，詳細參考提供的維基百科連結
	
### 機率分布：離散分布與連續分布
---

關於[機率分布](https://zh.wikipedia.org/wiki/概率分布#伽马分布)主要分為兩種：

離散分布：值域是離散的，例如：擲硬幣，結果有正面與反面

常見的離散分布有：`二項分布`

{% include widget/photo.html url="https://upload.wikimedia.org/wikipedia/commons/thumb/7/75/Binomial_distribution_pmf.svg/600px-Binomial_distribution_pmf.svg.png" description="from 維基百科" %}

連續分布：值域是連續的，例如：人類的身高分布

常見的連續分布有：`常態分布`

{% include widget/photo.html url="https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/650px-Normal_Distribution_PDF.svg.png" description="from 維基百科" %}

最好可以記一下每種分布所對應到的`pmf`或是`pdf`


### 最大似然估計(Maximum Likelihood Estimation)
---

了解了什麼是`似然函數(Likelihood Function)`之後

求`最大似然(Maximum Likelihood)`

也就是在某一機率分布下，最有可能的參數

根據[維基百科](https://zh.wikipedia.org/wiki/最大似然估计)所舉的例子

可以分為三種組合

1. 離散分布，離散有限參數空間
2. 離散分布，連續參數空間
3. 連續分布，連續參數空間

---

第一種情況，我們的參數由於`離散而且有限`

所以我們理論上能試過所有可能的機率，取最大值

---

第二種情況：`離散分布，連續參數空間`

我一開始在這邊有點疑問，連續的參數空間，怎麼使得結果是離散分布呢？

舉維基的例子來說，假設我們今天準備了無數個硬幣，每個硬幣擲到正面的機率p分布在0到1，而每個p都有對應到該機率的硬幣，假設今天隨機拿一個硬幣骰了100次，得到正面40次，反面60次的觀測結果

我們記為H=40，T=60，可以求`Likelihood`：

$$ L(θ \mid H=40,T=60) = P(H=40,T=60 \mid p) = C(100,40) * p^{40} * (1-p)^{60} \textit{(二項分布)} $$

所以，接下來我們要求得`似然函式L`在0~1之間的最大值

由於L是個`連續函數`，我們要求得導函數為零的值，於是

$$ C(100,40) \times (40 \times p^{39} \times (1-p)^{60} - 60 \times p^{40} \times (1-p)^{59}) = 0 $$

$$ p^{39} \times (1-p)^{59} \times ( 40 \times (1-p) - 60 \times p) = 0 $$

$$  p^{39} \times (1-p)^{59} \times (-100p + 40) = 0 $$

所以可以得出，$p = 0, 1, \frac{40}{100}$

0, 1不可能，因為會使得L為0，所以$p = \frac{40}{100}$時是Maximum Likelihood

由此我們也能歸納出，二項分布的最大似然估計值為

$$ MLE = \frac{t}{N} $$

$$ t \textit{為正面（成功）的次數，} N \textit{為總次數} $$

我們再回到剛剛說的連續參數空間，為什麼卻是離散分布的問題

我們上述整個過程都是在對`似然函數L`做操作

而似然函數的分布是連續的沒錯，但所謂的離散指的是`值域`的離散

這邊的結果只會有正面跟反面，不像身高、智商、體重等等呈現連續分布

---

第三種情況：`連續分布，連續參數空間`

舉常態分布為例

我們發現到，控制的參數有兩個$ \mu $, $ \sigma^{2} $

等一下做導函數時，需要分別做`偏微分`即可

另外值得一提的是，我們通常會取自然對數再求導函數

因為在似然函數L的值域中(0~1)，自然對數是`嚴格遞增的上凸函數`

所以求似然函數的最大值跟取完自然對數後的最大值是等價的

這邊的計算較繁雜，可以參考[維基即可](https://zh.wikipedia.org/wiki/最大似然估计)

### References
---

1. PRML-Chapter 2
2. Wiki
3. Saeed-Ghahramani-Fundamentals-of-Probability

